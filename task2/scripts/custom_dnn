#!/usr/bin/python3

import sys
import rospy
import cv2
import numpy as np
from numpy.linalg import norm
# import sensor_msgs.point_cloud2 as pc2
# from sklearn.decomposition import PCA
# from sklearn.cluster import DBSCAN
import tf2_geometry_msgs
import tf2_ros

# import pygame
from os.path import dirname, join
from matplotlib import use
import matplotlib.pyplot as plt
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped, Vector3, Pose, PoseWithCovarianceStamped, PoseStamped
from cv_bridge import CvBridge, CvBridgeError
from visualization_msgs.msg import Marker, MarkerArray
from std_msgs.msg import ColorRGBA
from std_msgs.msg import String


from sound_play.libsoundplay import SoundClient

from std_msgs.msg import Int8

use('GTK3Agg')



def cosine_distance(v1 : np.ndarray, v2: np.ndarray) -> float:
    return 1 - np.dot(v1, v2) / (norm(v1) * norm(v2))


def euclidean_distance(x1, y1, x2, y2) -> float:
    return np.sqrt((x1-x2)**2 + (y1-y2)**2)


class face_localizer:
    def __init__(self):
        # init rospy node called face_localizer
        rospy.init_node('face_localizer', anonymous=True)

        # An object we use for converting images between ROS format and OpenCV format
        self.bridge = CvBridge()

        # The function for performin HOG face detection
        #self.face_detector = dlib.get_frontal_face_detector()
        protoPath = join(dirname(__file__), "deploy.prototxt.txt")
        modelPath = join(dirname(__file__), "res10_300x300_ssd_iter_140000.caffemodel")

        self.face_net = cv2.dnn.readNetFromCaffe(protoPath, modelPath)

        # A help variable for holding the dimensions of the image
        self.dims = (0, 0, 0)

        # Marker array object used for showing markers in Rviz
        self.marker_array = MarkerArray()
        self.marker_num = 1
        self.desired_no_of_detections = 2 # previously 3, task2 doesn't state number of faces.

        # Subscribe to the image and/or depth topic
        # self.image_sub = rospy.Subscriber("/camera/rgb/image_raw", Image, self.image_callback)
        # self.depth_sub = rospy.Subscriber("/camera/depth/image_raw", Image, self.depth_callback)
        

        # current robot location
        self.x = 0
        self.y = 0
        self.z_ang = 0
        self.w_ang = 0

        # Publiser for the visualization markers
        self.markers_pub = rospy.Publisher('all_faces', MarkerArray, queue_size=1000)
        self.face_and_cylinder_status_pub = rospy.Publisher('/face_and_cylinder_status', Int8, queue_size=5) # !!!!!!!!!
        # Publishers for movement and robot pose location
        self.approach_pub = rospy.Publisher('/move_base_simple/goal', PoseStamped, queue_size=20)
        self.curr_location = rospy.Subscriber("/amcl_pose", PoseWithCovarianceStamped, self.curr_location_callback)

        # self.sound_pub = rospy.Publisher("/sound_play/goal", SoundRequest, queue_size=10)

        # Object we use for transforming between coordinate frames
        self.tf_buf = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buf)

        self.sound_handle = SoundClient()
        # rospy.sleep(1)
        self.sound = self.sound_handle.waveSound("/home/inner/Sola/rins/work/src/StickEmUp.wav", volume=1)


    def curr_location_callback(self, msg: PoseWithCovarianceStamped):
        self.x = msg.pose.pose.position.x
        self.y = msg.pose.pose.position.y
        self.z_ang = msg.pose.pose.orientation.z
        self.w_ang = msg.pose.pose.orientation.w



    def get_pose(self,coords,dist,stamp):
        # Calculate the position of the detected face in the coordinate system
        ## Above line lies, it actually returns relative position to the robot.
        ## to obtain the absolute position, we need to transform relative position by adding robot position.

        k_f = 554 # kinect focal length in pixels

        x1, x2, y1, y2 = coords

        face_x = self.dims[1] / 2 - (x1+x2)/2.
        face_y = self.dims[0] / 2 - (y1+y2)/2.

        angle_to_target = np.arctan2(face_x,k_f)

        # Get the angles in the base_link relative coordinate system
        x, y = dist*np.cos(angle_to_target), dist*np.sin(angle_to_target)

        ### Define a stamped message for transformation - directly in "base_link"
        #point_s = PointStamped()
        #point_s.point.x = x
        #point_s.point.y = y
        #point_s.point.z = 0.3
        #point_s.header.frame_id = "base_link"
        #point_s.header.stamp = rospy.Time(0)

        # Define a stamped message for transformation - in the "camera rgb frame"
        point_s = PointStamped()
        point_s.point.x = -y
        point_s.point.y = 0
        point_s.point.z = x
        point_s.header.frame_id = "camera_rgb_optical_frame"
        point_s.header.stamp = stamp


        # Get the point in the "map" coordinate system
        try:
            point_world = self.tf_buf.transform(point_s, "map")

            # Create a Pose object with the same position
            pose = Pose()
            pose.position.x = point_world.point.x
            pose.position.y = point_world.point.y
            pose.position.z = point_world.point.z
        except Exception as e:
            print(e)
            pose = None

        return pose
    
    def check_if_tagged(self, new_marker):
        for idx, marker in enumerate(self.marker_array.markers):
        # Ugly disgusting assignments, so it's a bit more readable down the line
            x_new = new_marker.pose.position.x
            y_new = new_marker.pose.position.y
            x_old = marker.pose.position.x
            y_old = marker.pose.position.y

            distance = euclidean_distance(x_new, y_new, x_old, y_old)  # calc distance between possible markers
            print("Distance between new and marker with idx %d: %d", idx, distance)  # sanity check print

            if (distance < 0.32):   # marker array of detected faces
                new_marker.id = marker.id
                marker = new_marker
                return True

        # assume new marker:
        self.marker_array.markers.append(new_marker)
        print("Face detected is not tagged yet, adding new marker")
        return False

        # If the new marker is close to an old marker, we don't add it, as it is probably a duplicate
        

    def find_faces(self):
        # print('I got a new image!')

        # Get the next rgb and depth images that are posted from the camera
        try:
            rgb_image_message = rospy.wait_for_message("/camera/rgb/image_raw", Image)
        except Exception as e:
            print(e)
            return 0

        try:
            depth_image_message = rospy.wait_for_message("/camera/depth/image_raw", Image)
            # print(depth_image_message.encoding)
        except Exception as e:
            print(e)
            return 0
        
        # try:
        #     cloud_msg = rospy.wait_for_message("/camera/depth/points", pc2.PointCloud2)
        #     # print(cloud_msg.encoding)
        # except Exception as e:
        #     print(e)
        #     return 0

        # Convert the images into a OpenCV (numpy) format

        try:
            rgb_image = self.bridge.imgmsg_to_cv2(rgb_image_message, "bgr8")
        except CvBridgeError as e:
            print(e)

        try:
            depth_image = self.bridge.imgmsg_to_cv2(depth_image_message, "32FC1")
        except CvBridgeError as e:
            print(e)

        # Set the dimensions of the image
        self.dims = rgb_image.shape
        h = self.dims[0]
        w = self.dims[1]

        # Tranform image to gayscale
        #gray = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2GRAY)

        # Do histogram equalization
        #img = cv2.equalizeHist(gray)

        # Detect the faces in the image
        #face_rectangles = self.face_detector(rgb_image, 0)
        blob = cv2.dnn.blobFromImage(cv2.resize(rgb_image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))
        self.face_net.setInput(blob)
        face_detections = self.face_net.forward()

        for i in range(0, face_detections.shape[2]):
            confidence = face_detections[0, 0, i, 2]
            # print("current face_confidence = ", confidence)
            if confidence>0.80:
                box = face_detections[0,0,i,3:7] * np.array([w,h,w,h])
                box = box.astype('int')
                x1, y1, x2, y2 = box[0], box[1], box[2], box[3]

                # Extract region containing face
                face_region = rgb_image[y1:y2, x1:x2]

                # Visualize the extracted face
                #cv2.imshow("ImWindow", face_region)
                #cv2.waitKey(1)

                # Find the distance to the detected face
                face_distance = float(np.nanmean(depth_image[y1:y2,x1:x2]))

                print('Distance to face', face_distance)


                # Get the time that the depth image was recieved
                depth_time = depth_image_message.header.stamp

                # Find the location of the detected face
                pose = self.get_pose((x1,x2,y1,y2), face_distance, depth_time)


                if pose is not None:

                    # Create a marker used for visualization
                    # using relative coordinates of pose
                    num = self.marker_num + 1
                    marker = Marker()
                    marker.header.stamp = rospy.Time(0)
                    marker.header.frame_id = 'map'
                    marker.pose = pose
                    marker.type = Marker.CUBE
                    marker.action = Marker.ADD
                    marker.frame_locked = False
                    marker.lifetime = rospy.Duration.from_sec(10)
                    marker.id = num
                    marker.scale = Vector3(0.1, 0.1, 0.1)
                    marker.color = ColorRGBA(0, 1, 0, 1)

                    if (face_distance < 1.3):
                        already_detected = self.check_if_tagged(marker)
                        print("Already detected result: ",  already_detected)
                        if already_detected:
                            print('Face already marked!')
                        else:
                            self.marker_num += 1
                            # if the face hasn't been marked yet, we marked it inside of already_detected
                            # so we can just show the face.
                            face_region = rgb_image[y1:y2, x1:x2]
                            face_region = cv2.cvtColor(face_region, cv2.COLOR_BGR2RGB)
                            x_snap = self.x
                            y_snap = self.y
                            w_snap = self.w_ang;
                            z_snap = self.z_ang;
                            # plt.imshow(face_region)
                            # plt.axis('off')
                            # plt.show()
                            # plt.waitforbuttonpress(timeout=3)  # bad idea
                            # here implement proper approach. First build PoseStamped message, then publish it to
                            # /move_base_simple/goal topic using self.approach_pub.publish(msg)
                            new_goal = self.create_approach_goal(marker, x_snap, y_snap, z_snap, w_snap)
                            # print("MARKER POSE: x:%f, y:%f, z:%f, w:%f\n", (marker.pose.position.x, marker.pose.position.y, marker.pose.orientation.z, marker.pose.orientation.w))
                            self.approach_pub.publish(new_goal)
                            self.sound.play()
                            print("New face detected: Initiating approach to face")
                            # point_cloud = []
                            # for point in pc2.read_points(cloud_msg, skip_nans=True):
                            #     point_cloud.append([point[0], point[1], point[2]])
                            # point_cloud = np.asarray(point_cloud)

                            # print(point_cloud.shape)

                            # tf_buffer = tf2_ros.Buffer()
                            # tf_listener = tf2_ros.TransformListener(tf_buffer)


                            plt.imshow(face_region)
                            plt.axis('off')
                            plt.show()
                            ## need current robot position
                            
                        if self.marker_num == 1 + self.desired_no_of_detections: # because of course we start counting at 1, what is this... R? What is life ?
                            
                            self.face_and_cylinder_status_pub.publish(1) # if all found
                            
                            # kill = String()
                            # kill.data = "%d faces detected, time to die, map_goals" % self.desired_no_of_detections
                            # print(kill.data)
                            # self.kill_pub.publish(kill)
                            
        self.markers_pub.publish(self.marker_array)


    def create_approach_goal(self, marker, x_snap, y_snap, z_snap,  w_snap):
        new_goal = PoseStamped()
        new_goal.header.stamp = rospy.Time.now();
        new_goal.header.frame_id = 'map'
        new_goal.pose.position.x = (x_snap + marker.pose.position.x) / 2
        new_goal.pose.position.y = (y_snap + marker.pose.position.y) / 2
        new_goal.pose.orientation.z = z_snap
        new_goal.pose.orientation.w = w_snap

        return new_goal


    def depth_callback(self,data): 

        try:
            depth_image = self.bridge.imgmsg_to_cv2(data, "32FC1")
        except CvBridgeError as e:
            print(e)

        # Do the necessairy conversion so we can visuzalize it in OpenCV
        
        image_1 = depth_image / np.nanmax(depth_image)
        image_1 = image_1*255
        
        image_viz = np.array(image_1, dtype=np.uint8)

        #cv2.imshow("Depth window", image_viz)
        #cv2.waitKey(1)

        #plt.imshow(depth_image)
        #plt.show()
        



def main():
        
        # pygame.init()
        

        face_finder = face_localizer()

        rate = rospy.Rate(1)
        while not rospy.is_shutdown():
            face_finder.find_faces()
            rate.sleep()

        cv2.destroyAllWindows()


if __name__ == '__main__':
    main()
