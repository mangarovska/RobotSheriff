#!/usr/bin/python3

import sys
import rospy
import cv2
import numpy as np
import tf2_geometry_msgs
import tf2_ros
from sensor_msgs.msg import Image
from std_msgs.msg import String
from geometry_msgs.msg import PointStamped, Vector3, Pose, PoseStamped
from cv_bridge import CvBridge, CvBridgeError
from visualization_msgs.msg import Marker, MarkerArray
from std_msgs.msg import ColorRGBA
from task2.msg import poseWithCovarString
import webcolors
from collections import Counter

## time to add proof that we are mapping colors to strings.
# from sound_play.msg import SoundRequest
# from sound_play.libsoundplay import SoundClient

name_mapping = {"lime" : "green",
                "green": "green",
                "gray" : "blue",
                "black" : "black",
                "silver": "blue",
                "olive" : 'red',
                "red" : "red",
                "orange" : "red",
                "teal" : "blue"}


color_mapping = {"green" : np.array([0, 255, 0]),
                    "blue" :  np.array([0, 255, 255]),
                    "red" :  np.array([255, 0, 0]),
                    "black" :  np.array([0, 0, 0])}

class The_Ring:
    def __init__(self):
        rospy.init_node('image_converter', anonymous=True)

        # An object we use for converting images between ROS format and OpenCV format
        self.bridge = CvBridge()

        # A help variable for holding the dimensions of the image
        self.dims = (0, 0, 0)

        # Marker array object used for visualizations
        self.marker_array = MarkerArray()
        self.marker_num = 1

        # Subscribe to the image and/or depth topic
        self.image_sub = rospy.Subscriber("/arm_camera/rgb/image_raw", Image, self.image_callback)
        # self.depth_sub = rospy.Subscriber("/camera/depth/image_raw", Image, self.depth_callback)

        # Publisher for the visualization markers
        self.markers_pub = rospy.Publisher('all_rings', MarkerArray, queue_size=1000)
        self.ring_detection_pub = rospy.Publisher('/ring_status/ring', PoseStamped, queue_size=20)
        self.robot_position_pub = rospy.Publisher('/ring_status/robot', PoseStamped, queue_size=20)
        self.vocalizer_pub = rospy.Publisher('/vocalizer_req', String, queue_size=1000)
        self.ring_pose_color_pub = rospy.Publisher('/ring_pose_n_color', poseWithCovarString, queue_size=20)

        
        # Object we use for transforming between coordinate frames
        self.tf_buf = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buf)

        # Hardcoded grey color
        self.hardcoded_grey = np.array([178,178,178])
        
        # storage for confirmed marker list
        self.confirmed_marker_list = []
        self.pending_marker_list = []

        self.pending_marker_dict = {
                                    'green' : [],
                                    'red'   : [],
                                    'blue'  : [],
                                    'black' : []
                                    }

        self.pending_pose = []
        self.colorsave = []

        # We need to hold the locale of the green ring, for later use:
        self.green_ring_position = None
        self.robot_position_at_detection = None

        self.sign = 0
        self.desired_number_of_rings = 4 # should be 4, as that's the number on map.

        # Sound client for playing sounds
        # self.soundhandle = SoundClient()
        # self.voice = 'voice_kal_diphone'
        # self.volume = 1.0


    def marker_maker(self, pose, point_world, rgba_list=[1,0,0,1]) :
        self.marker_num += 1
        marker = Marker()
        marker.header.stamp = point_world.header.stamp
        marker.header.frame_id = point_world.header.frame_id
        marker.pose = pose
        marker.type = Marker.SPHERE
        marker.action = Marker.ADD
        marker.frame_locked = False
        marker.lifetime = rospy.Duration.from_sec(10)
        marker.id = self.marker_num
        marker.scale = Vector3(0.2, 0.2, 0.2)
        marker.color = ColorRGBA(rgba_list[0],rgba_list[1],rgba_list[2],rgba_list[3])
        self.marker_array.markers.append(marker)

        self.markers_pub.publish(self.marker_array)


    def bgr_2_rgb(self, color_vect):
        return cv2.cvtColor(np.uint8([[color_vect]]), cv2.COLOR_BGR2RGB)[0][0]
    

    def closest_colour(self, rgb_triplet):
        min_colours = {}
        for key, name in webcolors.CSS21_HEX_TO_NAMES.items():
            r_c, g_c, b_c = webcolors.hex_to_rgb(key)
            rd = (r_c - rgb_triplet[0]) ** 2
            gd = (g_c - rgb_triplet[1]) ** 2
            bd = (b_c - rgb_triplet[2]) ** 2
            min_colours[(rd + gd + bd)] = name
        return min_colours[min(min_colours.keys())]
    

    # def detect_and_show_majority_color(self, image_excerpt) :

    #     ## DEBUG MODE 
    #     cv2.imshow("Circle excerpt", image_excerpt)
    #     cv2.waitKey(1)
    #     ## END DEBUG MODE
        
    #     masked_colors = np.ma.masked_equal(image_excerpt, self.hardcoded_grey)
    #     # masked_colors = np.ma.masked_equal(image_excerpt, self.hardcoded_grey)

    #     mean_color = np.mean(masked_colors, axis=(0,1))
    #     print("Mean color: " , mean_color)

    #     ### DEBUG MODE 
    #     sample_matrix = np.zeros([300, 300, 3])
    #     sample_matrix[:,:] = mean_color
    #     cv2.imshow("Mean color: ", sample_matrix.astype(np.uint8))
    #     cv2.waitKey(1)
    #     ### END DEBUG MODE

    #     # self.colorsave.append(mean_color)

    #     return mean_color

    def detect_and_show_majority_color(self, image_excerpt) :

        ## DEBUG MODE 
        cv2.imshow("Circle excerpt", image_excerpt)
        cv2.waitKey(1)
        ## END DEBUG MODE
        flattened_image = image_excerpt.reshape(-1, 3)

        excluded_colors = np.array([self.hardcoded_grey, [255, 255, 255]])
        mask = np.isin(flattened_image, excluded_colors).all(axis=1)
        filtered_pixels = flattened_image[~mask]

        # mean_color = np.mean(filtered_pixels, axis=0) 
        color_counter = Counter(tuple(map(tuple, filtered_pixels)))
        majority_color = color_counter.most_common(1)[0][0]
        print("Majority color: " , majority_color)

        sample_matrix = np.zeros([300, 300, 3])
        ### DEBUG MODE 
        sample_matrix[:,:] = majority_color
        cv2.imshow("Mean color: ", sample_matrix.astype(np.uint8))
        cv2.waitKey(1)
        ### END DEBUG MODE

        # self.colorsave.append(mean_color)

        return majority_color


    def append_to_pending(self, loc_vector):
        # if pending list empty simply add:
        if len(self.pending_marker_list) == 0:
            self.pending_marker_list.append(loc_vector)
            return True
        else:
            # check if the marker is close enough to current pending list
            distance_vect = np.linalg.norm(np.array(self.pending_marker_list) - loc_vector, axis=1)
            # print(distance_vect)
            if(distance_vect < 0.10).all():  # prev 0.25 || latest 0.2, worked, but at what cost
                # if the distance between all components is sufficiently small, add our new marker to the list
                self.pending_marker_list.append(loc_vector)
                return True
            else:
                # distance between all components is too large, reset our pending list, and return false
                self.pending_marker_list.clear()
                return False
            

    def append_to_pending_dict(self, loc_vector, mapped_string):
        # if pending list empty simply add:
        if len(self.pending_marker_dict[mapped_string]) == 0:
            self.pending_marker_dict[mapped_string].append(loc_vector)
            return True
        else:
            # check if the marker is close enough to current pending list
            distance_vect = np.linalg.norm(np.array(self.pending_marker_dict[mapped_string]) - loc_vector, axis=1)
            # print(distance_vect)
            if(distance_vect < 0.15).all():  # prev 0.25 || latest 0.2, worked, but at what cost || 16
                # if the distance between all components is sufficiently small, add our new marker to the list
                self.pending_marker_dict[mapped_string].append(loc_vector)
                return True
            else:
                # distance between all components is too large, reset our pending list, and return false
                self.pending_marker_dict[mapped_string].clear()
                return False
            

    def marker_pose_creator(self):
        self.marker_num += 1
        marker = Marker()
        marker.header.stamp = rospy.Time(0)
        marker.header.frame_id = "map"
        marker.pose.position = self.robot_position_at_detection.translation
        marker.pose.orientation = self.robot_position_at_detection.rotation
        marker.type = Marker.ARROW
        marker.action = Marker.ADD
        marker.frame_locked = False
        marker.lifetime = rospy.Duration.from_sec(10)
        marker.id = self.marker_num
        marker.scale = Vector3(0.2, 0.2, 0.2)
        marker.color = ColorRGBA(0,0,1,1)
        self.marker_array.markers.append(marker)

        self.markers_pub.publish(self.marker_array)
    

    def append_to_confirmed(self):
        # if confirmed list empty simply add:
        mean_loc = np.mean(np.array(self.pending_marker_list), axis=0)
        print(mean_loc)
        if len(self.confirmed_marker_list) == 0:
            self.confirmed_marker_list.append(mean_loc)
            self.pending_pose = mean_loc
            return True
        else:
            # check if the marker isn't already within our confirmed list
            distance_vect = np.linalg.norm(np.array(self.confirmed_marker_list) - mean_loc, axis=1)
            if (distance_vect <= 0.48).any():  # old: <0.4 || latest = 0.5
                # The distance between our new marker and all confirmed markers is too small, this is a duplicate.
                # clear our pending list and return false
                self.pending_marker_list.clear()
                return False
            else:
                # The distance between our new marker and all confirmed markers is sufficiently large, add our new marker to the list
                self.confirmed_marker_list.append(mean_loc)
                self.pending_pose = mean_loc
                return True
            
    def append_to_confirmed_dict(self, mapped_string):
        # if confirmed list empty simply add:
        mean_loc = np.mean(np.array(self.pending_marker_dict[mapped_string]), axis=0)
        print(mean_loc)
        if len(self.confirmed_marker_list) == 0:
            print("First marker added to confirmed list")
            self.confirmed_marker_list.append(mean_loc)
            self.colorsave.append(mapped_string)
            self.pending_pose = mean_loc
            return True
        else:
            # check if the marker isn't already within our confirmed list
            print("Checking if marker is already in confirmed list")
            distance_vect = np.linalg.norm(np.array(self.confirmed_marker_list) - mean_loc, axis=1)
            if (distance_vect <= 0.48).any() or mapped_string in self.colorsave:  # old: <0.4 || latest = 0.5
                # The distance between our new marker and all confirmed markers is too small, this is a duplicate.
                # clear our pending list and return false
                print("distance_vector", distance_vect)
                print("Marker is already in confirmed list")
                self.pending_marker_dict[mapped_string].clear()
                return False
            else:
                print("Marker is not in confirmed list yet, yay")
                # The distance between our new marker and all confirmed markers is sufficiently large, add our new marker to the list
                self.confirmed_marker_list.append(mean_loc)
                self.colorsave.append(mapped_string)
                self.pending_pose = mean_loc
                return True
            
    

    def get_robot_pose(self):
        """
        Get the pose of the robot in the global frame.
        Set the global pose to represent the pose of the robot in the global frame.
        Format of the global pose is PoseStamped:
        global_pose.translation is our position in the global frame.
        global_pose.rotation is our orientation in the global frame in quarterion format.
        """
        transformed= self.tf_buf.lookup_transform("map", "base_link", rospy.Time(0), rospy.Duration(10.0))
        # print(transformed)
        self.robot_position_at_detection = transformed.transform
        if self.sign == 0:
            if self.robot_position_at_detection.rotation.w >= 0:
                self.sign = 1
            else:
                self.sign = -1
       
    def get_pose(self, e, dist):
        # Calculate the position of the detected ellipse

        k_f = 525 # kinect focal length in pixels

        elipse_x = self.dims[1] / 2 - e[0][0]
        elipse_y = self.dims[0] / 2 - e[0][1]

        angle_to_target = np.arctan2(elipse_x, k_f)

        # Get the angles in the base_link relative coordinate system
        x, y = dist*np.cos(angle_to_target), dist*np.sin(angle_to_target)

        ### Define a stamped message for transformation - directly in "base_frame"
        #point_s = PointStamped()
        #point_s.point.x = x
        #point_s.point.y = y
        #point_s.point.z = 0.3
        #point_s.header.frame_id = "base_link"
        #point_s.header.stamp = rospy.Time(0)

        # Define a stamped message for transformation - in the "camera rgb frame"
        point_s = PointStamped()
        point_s.point.x = -y
        point_s.point.y = 0
        point_s.point.z = x
        point_s.header.frame_id = "camera_rgb_optical_frame"
        point_s.header.stamp = rospy.Time(0)

        try:
            # rospy.wait_for_service('tf', timeout = 10)
            # Get the point in the "map" coordinate system
            point_world = self.tf_buf.transform(point_s, "map")

            # Create a Pose object with the same position
            pose = Pose()
            pose.position.x = point_world.point.x
            pose.position.y = point_world.point.y
            pose.position.z = point_world.point.z

            return pose, point_world

        except Exception as e:
            print(e)
            pose = None




    def image_callback(self, data):
        # print('I got a new image!')

        try:
            cv_image = self.bridge.imgmsg_to_cv2(data, "bgr8")
        except CvBridgeError as e:
            print(e)

        # Set the dimensions of the image
        # print(f"cv_image_shape: {cv_image.shape}")
        self.dims = cv_image.shape
        cv_image = cv_image[0:300, :]

        self.dims = cv_image.shape
        alpha = 1.8 # Contrast control
        beta = -100 # Brightness control
        adjusted = cv2.convertScaleAbs(cv_image, alpha=alpha, beta=beta)
        # adjusted = cv_image

        # Tranform image to gayscale
        gray = cv2.cvtColor(adjusted, cv2.COLOR_BGR2GRAY)

        # Do histogram equlization
        img = cv2.equalizeHist(gray)

        # Binarize the image, there are different ways to do it
        #ret, thresh = cv2.threshold(img, 50, 255, 0)
        # ret, thresh = cv2.threshold(img, 201, 255, cv2.THRESH_BINARY)
        # ret, thresh = cv2.threshold(img, 170, 255, cv2.THRESH_BINARY)
        # thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 25)  #default: 15,25
        thresh = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 15, 25)  #default: 15,25

        cv2.imshow("thresh", thresh)
        cv2.waitKey(1)

        # Extract contours
        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        # contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_TC89_L1)
        # contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_TC89_KCOS)

        # Fit elipses to all extracted contours
        elps = []
        for cnt in contours:
            #     print cnt
            #     print cnt.shape
            if cnt.shape[0] >= 20:
                ellipse = cv2.fitEllipse(cnt)
                elps.append(ellipse)

        # print(elps[0])
        
        # Find two elipses with same centers
        candidates = []
        for n in range(len(elps)):
            e1 = elps[n]
            # if e1[0][1] > 100: continue
            for m in range(n + 1, len(elps)):
                e2 = elps[m]
                # if e2[0][1] > 100: continue

                dist = np.sqrt(((e1[0][0] - e2[0][0]) ** 2 + (e1[0][1] - e2[0][1]) ** 2))
                e1_shape = np.array(e1[1])
                e2_shape = np.array(e2[1])

                e1_aspect_ratio = e1_shape.max() / (e1_shape.min()+1)
                e2_aspect_ratio = e2_shape.max() / (e2_shape.min()+1)

                aspect_ratio_diff = abs(e1_aspect_ratio - e2_aspect_ratio)


                # print("aspect ratio e1: ", e1_aspect_ratio, "aspect ratio e2: ", e2_aspect_ratio, "aspect ratio diff: ", aspect_ratio_diff)
                #             print dist
                if dist < 4:  # and aspect_ratio_diff < 0.3:  # e1_aspect_ratio < 1.4 and e2_aspect_ratio < 1.4
                    candidates.append((e1,e2))

        # print("Processing is done! found", len(candidates), "candidates for rings")

        try:
            depth_img = rospy.wait_for_message('/arm_camera/depth/image_raw', Image)   
        except Exception as e:
            print(e)

        # test1, test2 = candidates[0]
        # print(test1)
        # Extract the depth from the depth image
        ring_flag = False
        for c in candidates:
            # print(c[0])

            # the centers of the ellipses
            e1, e2 = c
            el1 = np.array(e1[1])
            el2 = np.array(e2[1])
            e1_aspect_ratio = el1.max() / el1.min()
            e2_aspect_ratio = el2.max() / el2.min()

            aspect_ratio_diff = abs(e1_aspect_ratio - e2_aspect_ratio)

            # print("aspect ratio e1: ", e1_aspect_ratio, "aspect ratio e2: ", e2_aspect_ratio, "aspect ratio diff: ", aspect_ratio_diff)

            # if (cv_image[0][1] == )

            # drawing the ellipses on the image
            # delay until you are certain it's a good detection
            # cv2.ellipse(cv_image, e1, (0, 0, 0), 2)
            # cv2.ellipse(cv_image, e2, (0, 0, 0), 2)
            cv2.imshow("Elipse contours", cv_image)
            cv2.waitKey(1)

            size = (e1[1][0] + e1[1][1])/2
            center = (e1[0][1], e1[0][0])

            x1 = int(center[0] - size / 2)
            x2 = int(center[0] + size / 2)
            x_min = x1 if x1>0 else 0
            x_max = x2 if x2<cv_image.shape[0] else cv_image.shape[0]

            y1 = int(center[1] - size / 2)
            y2 = int(center[1] + size / 2)
            y_min = y1 if y1 > 0 else 0
            y_max = y2 if y2 < cv_image.shape[1] else cv_image.shape[1]

            depth_image = self.bridge.imgmsg_to_cv2(depth_img, "passthrough")

            # if center distance is presumed to be 0, or some variation of nan
            # the ring has a hole, therefore it's indeed a 3d ring.
            center_idx = np.rint(center).astype(int)
            # print("center dist: ", depth_image[center_idx[0], center_idx[1]])

            # another guarantee:
            # print("Center pixel bgr value: ", cv_image[center_idx[0], center_idx[1]])
            # color_vect =  cv_image[center_idx[0], center_idx[1]]


            # masked_depth = np.ma.masked_equal(depth_image[x_min:x_max,y_min:y_max], 0)
            ring_dist= float(np.nanmean(depth_image[x_min:x_max,y_min:y_max]))
            # print(f"Distance to ring : {ring_dist}")
            # cv2.imshow("Depth", depth_image)
            # cv2.waitKey(0)

            color_vect =  cv_image[center_idx[0], center_idx[1]]
            # print(color_vect)
            
            true_ring = False or (np.isnan(depth_image[center_idx[0], center_idx[1]]) and (np.sum(cv_image[center_idx[0], center_idx[1]]) <= 755) and np.array_equal(self.hardcoded_grey, color_vect)) # 255+255+255 = 765
            ring_flag = true_ring and ring_dist < 2.0
            mapped_string = None
            """
            - Only after the if statement are we certain that it's a proper detection,
            - finally we can start manipulating elements as intended.
            """
            if true_ring and ring_dist < 2.0 and aspect_ratio_diff < 1.1:  # prev 3.3
                print(f"Aspect ratio 1: {e1_aspect_ratio}, aspect ratio 2: {e2_aspect_ratio}, aspect ratio diff: {aspect_ratio_diff}")
                copy = cv_image.copy()
                cv2.ellipse(copy, e1, (0, 255, 0), 2)
                cv2.ellipse(copy, e2, (0, 255, 0), 2)
                color_vect =  cv_image[center_idx[0], center_idx[1]]


                # cv2.imshow("Circle excerpt", image_excerpt)
                # cv2.waitKey(0)
                pose_temp, point_world = self.get_pose(e1, ring_dist)

                # firstly, if the pending_marker_list is empty, we can just add the marker to the list
                curr_pose_vector = np.array([pose_temp.position.x, pose_temp.position.y, pose_temp.position.z])
                
                image_excerpt = cv_image[x_min:x_max,y_min:y_max]
                color_vect = self.detect_and_show_majority_color(image_excerpt)

                rgb = self.bgr_2_rgb(color_vect)

                string = self.closest_colour(rgb)
                print("String: ", string)
                mapped_string = name_mapping[string]


                # print(self.append_to_pending(curr_pose_vector))
                print(self.append_to_pending_dict(curr_pose_vector, mapped_string))
                

                if(len(self.pending_marker_dict[mapped_string]) >= 5): ## min 7 b4 >6  || latest >=8 || this is horrible idea :DDDD
                    # we have enough detections, so we can add the marker to the marker_list
                    print("It's time to add to confirmed list")
                    if(self.append_to_confirmed_dict(mapped_string)):
                        print("success, or broken.")
                        ideal_marker_pose = Pose()
                        ideal_marker_pose.position.x = self.pending_pose[0]
                        ideal_marker_pose.position.y = self.pending_pose[1]
                        ideal_marker_pose.position.z = self.pending_pose[2]

                        # Show detected color andsave it to a list
                        image_excerpt = cv_image[x_min:x_max,y_min:y_max]
                        color_vect = self.detect_and_show_majority_color(image_excerpt)

                        # here we have to convert our color vector into a color name
                        rgb = self.bgr_2_rgb(color_vect)
                        # print("HSV color: ", hsv_color)
                        print("RGB color: ", rgb)
                        string = self.closest_colour(rgb)
                        print("string-premap, ", string)
                        print("string-postmap, ", mapped_string)

                        spoken_string = f"Detected {mapped_string} ring"

                        self.vocalizer_pub.publish(spoken_string)

                        
                        published_pose = PoseStamped()
                        published_pose.header.frame_id = "map"
                        published_pose.header.stamp = rospy.Time.now()
                        published_pose.pose = ideal_marker_pose

                        for idx in range(0, 5):
                            self.ring_pose_color_pub.publish(poseWithCovarString(published_pose, name_mapping[string]))

                        # lovely debug statement
                        print(f"ideal_marker_pose:\n\tx: {ideal_marker_pose.position.x}\n\ty: {ideal_marker_pose.position.y}\n\tz:{ideal_marker_pose.position.z}")

                        if (name_mapping[string] == "green"):
                            self.get_robot_pose()
                            # self.marker_pose_creator()
                            self.green_ring_position =[ideal_marker_pose.position.x, ideal_marker_pose.position.y, ideal_marker_pose.position.z] #[[ideal_pose.position.x, ideal_pose.position.y, ideal_pose.position.z], [self.x, self.y, self.z, self.w_ang, self.z]]
                            # point_world

                        if(len(self.confirmed_marker_list) >= self.desired_number_of_rings
                           and self.green_ring_position is not None 
                           and self.robot_position_at_detection is not None):
                            for i in range(0, 20):
                                current_message = PoseStamped()
                                current_message.header.frame_id = "map"
                                current_message.header.stamp = rospy.Time.now()

                                current_message.pose.position.x = self.green_ring_position[0]
                                current_message.pose.position.y = self.green_ring_position[1]
                                current_message.pose.position.z = self.green_ring_position[2]
                                current_message.pose.orientation.x = 0
                                current_message.pose.orientation.y = 0
                                current_message.pose.orientation.z = 0
                                current_message.pose.orientation.w = 0

                                self.ring_detection_pub.publish(current_message)

                                current_message.pose.position.x = self.robot_position_at_detection.translation.x
                                current_message.pose.position.y = self.robot_position_at_detection.translation.y
                                current_message.pose.position.z = self.robot_position_at_detection.translation.z
                                current_message.pose.orientation.x = self.robot_position_at_detection.rotation.x
                                current_message.pose.orientation.y = self.robot_position_at_detection.rotation.y
                                current_message.pose.orientation.z = self.robot_position_at_detection.rotation.z
                                current_message.pose.orientation.w = self.robot_position_at_detection.rotation.w
                                # self.ring_detection_pub
                                # self.robot_position_pub
                                self.robot_position_pub.publish(current_message)
                                   
                        rgba = np.append(color_mapping[name_mapping[string]]/255,1)
                        print(rgba)
                        self.marker_maker(ideal_marker_pose, point_world, rgba)

        # print("self.green_ring_position", self.green_ring_position)
        self.markers_pub.publish(self.marker_array)
                
        if len(candidates)>0 and ring_flag:
            print("Confirmed markers: ", self.confirmed_marker_list)
            if(mapped_string is not None):
                print("Pending markers for ",mapped_string, ": ", len(self.pending_marker_dict[mapped_string]))
            cv2.imshow("Image window", copy)
            cv2.waitKey(1)

    def depth_callback(self,data):
        # print("depth time aw yisss\n")
        try:
            depth_image = self.bridge.imgmsg_to_cv2(data, "16UC1")
        except CvBridgeError as e:
            print(e)

        # Do the necessairy conversion so we can visuzalize it in OpenCV
        image_1 = depth_image / 65536.0 * 255
        image_1 = image_1/np.max(image_1)*255

        image_viz = np.array(image_1, dtype= np.uint8)

        cv2.imshow("Depth window", image_viz)
        cv2.waitKey(1)


def main():

    ring_finder = The_Ring()

    try:
        rospy.spin()
    except KeyboardInterrupt:
        print("Shutting down")

    cv2.destroyAllWindows()


if __name__ == '__main__':
    main()
